{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import struct, csv, json, base64, zlib, pprint, numpy, ctypes, glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Relevant Python Documentation for Reading C Structs into Python](https://docs.python.org/3.5/library/struct.html \"Python Docs for C Structs\")\n",
    "\n",
    "#### [Excellent code snippets for working with Binary data in Python](https://www.devdungeon.com/content/working-binary-data-python \"DevDungeon\")\n",
    "\n",
    "|doc | url |\n",
    "|-----|-----|\n",
    "| adiBin docs| http://cdn.adinstruments.com/adi-web/manuals/translatebinary/LabChartBinaryFormat.pdf |\n",
    "| adiBin header|  http://cdn.adinstruments.com/adi-web/manuals/translatebinary/ADIBinaryFormat.h |\n",
    "| adiBin example|http://cdn.adinstruments.com/adi-web/manuals/translatebinary/TranslateBinary.c |\n",
    "|source | https://forum.adinstruments.com/viewtopic.php?t=395 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base64 to JSON function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base64ToJson(zippedString):\n",
    "    json_str = zlib.decompress(base64.b64decode(zippedString)).decode()\n",
    "    json_json = json.loads(json_str)\n",
    "    return json_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse CSV Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseCsv(csv_row, dbg=False):\n",
    "    \n",
    "    ############################################################################\n",
    "    # Parse CSV Data\n",
    "    ############################################################################\n",
    "    \n",
    "    # Record Identifiers \n",
    "    patient_id = csv_row[0]\n",
    "    time_since_admission = csv_row[1]\n",
    "    \n",
    "    # Decompress channel data\n",
    "    channel_json = base64ToJson(row[2])\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    # Parse file header and channel header data\n",
    "    ############################################################################\n",
    "    \n",
    "    # Number of channels\n",
    "    num_channels = len(channel_json)\n",
    "    \n",
    "    # Channel titles\n",
    "    channel_titles = []\n",
    "    for i in range(num_channels):\n",
    "        channel_titles.append(channel_json[i]['Label'].upper())\n",
    "        \n",
    "    \n",
    "\n",
    "    ############################################################################\n",
    "    # Parse channel data\n",
    "    ############################################################################\n",
    "    \n",
    "    # Convert channel data to list\n",
    "    channel_data = []\n",
    "    for i in range(num_channels):\n",
    "        channel_data.append([int(j) for j in channel_json[i]['Text'].split(',')])\n",
    "        \n",
    "    \n",
    "    # Check to see if all channels have the same length\n",
    "    # If channels are the same length, samples_per_channel set to len element 0\n",
    "    # If theres a mismatch, pad other channels with mean and\n",
    "    #   set samples_per_channel to max length\n",
    "    \n",
    "    if all(len(i) == len(channel_data[0]) for i in channel_data):\n",
    "        samples_per_channel = len(channel_data[0])\n",
    "        if dbg == True:\n",
    "            print(\"all channel_data sublists equal length\")\n",
    "    else:\n",
    "        max_sublist_len = len(max(channel_data, key=len))\n",
    "        for i in range (num_channels):\n",
    "            len_dif_tuple = (0, max_sublist_len - len(channel_data[i]))\n",
    "            channel_data[i] = numpy.pad(channel_data[i]\\\n",
    "                                        , pad_width = len_dif_tuple\\\n",
    "                                        , mode='mean'\n",
    "                                       )\n",
    "        samples_per_channel = max_sublist_len  \n",
    "        if dbg == True:\n",
    "            print(\"all channel_data sublists NOT equal length \\\n",
    "                  - padded w/ trailing means\")\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    # Create dictionary of all parsed data from csv file\n",
    "    ############################################################################\n",
    "    \n",
    "    csv_data = {\n",
    "          'patient_id' : patient_id\n",
    "        , 'time_since_admission' : time_since_admission\n",
    "        , 'num_channels' : num_channels\n",
    "        , 'channel_titles' : channel_titles\n",
    "        , 'channel_data' : channel_data\n",
    "        , 'samples_per_channel' : samples_per_channel\n",
    "    }\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    # Debug: Check values\n",
    "    ############################################################################\n",
    "    if dbg == True:\n",
    "        print(\"patient_id:\", patient_id)\n",
    "        print(\"time_since_admission:\", time_since_admission)\n",
    "        print(\"num_channels:\", num_channels)\n",
    "        print(\"channel_titles:\", channel_titles)\n",
    "        print(\"samples_per_channel:\", samples_per_channel)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    \n",
    "    ############################################################################\n",
    "    # Return\n",
    "    ############################################################################\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ADIBIN Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createAdibin(data_dict, dbg=False):\n",
    "    \n",
    "    ############################################################################\n",
    "    # Define default adibin file header variables\n",
    "    ############################################################################\n",
    "    \n",
    "    # Define default file size variables for writing adibin file\n",
    "    FILE_HEADER_LENGTH = 68\n",
    "    CHANNEL_HEADER_LENGTH = 96\n",
    "    CHANNEL_TITLE_LENGTH = 32\n",
    "    UNITS_LENGTH = 32\n",
    "    \n",
    "    # Define format strings for struct\n",
    "    ADI_FILE_HEADER_FORMAT_STRING = \"<4sldlllllddllll\"\n",
    "    ADI_CHANNEL_HEADER_FORMAT_STRING = \"<32s32sdddd\"\n",
    "    ADI_CHANNEL_DATA_FORMAT_STRING = \"<h\"\n",
    "    \n",
    "    # Define default file header variables\n",
    "    magic = b'CFWB'\n",
    "    version = 1\n",
    "    secs_per_tick = 1/240\n",
    "    year = 1776\n",
    "    month = 7\n",
    "    day = 4\n",
    "    hour = 0\n",
    "    minute = 0\n",
    "    second = 0\n",
    "    trigger = 0\n",
    "    # num_channels passed in dict\n",
    "    # samples_per_channel passed in dict\n",
    "    time_channel = 0\n",
    "    data_format = 3\n",
    "    \n",
    "    # Define default channel header variables\n",
    "    # channel_title passed in dict\n",
    "    units = {'I':b'mV' \\\n",
    "           , 'II':b'mV' \\\n",
    "           , 'III':b'mV' \\\n",
    "           , 'V':b'mV' \\\n",
    "           , 'AVR':b'mV' \\\n",
    "           , 'AVL':b'mV' \\\n",
    "           , 'AVF':b'mV'  \\\n",
    "           , 'AR2':b'mmHg' \\\n",
    "           , 'SPO2':b'%' \\\n",
    "           , 'RR':b'Imp' \\\n",
    "           , 'RESP':b'Imp'\\\n",
    "           }\n",
    "    scale = {'I': 2.44 \\\n",
    "           , 'II': 2.44 \\\n",
    "           , 'III': 2.44 \\\n",
    "           , 'V': 2.44 \\\n",
    "           , 'AVR': 2.44 \\\n",
    "           , 'AVL': 2.44 \\\n",
    "           , 'AVF': 2.44  \\\n",
    "           , 'AR2': 0.2 \\\n",
    "           , 'SPO2': 1.0 \\\n",
    "           , 'RR': 0.1 \\\n",
    "           , 'RESP': 0.1 \\\n",
    "           }\n",
    "    offset = 0\n",
    "    range_high = 1\n",
    "    range_low = 0\n",
    "    # channel_data passed in dict\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    # Create units and scales fields from channel titles  passed in dict\n",
    "    ############################################################################\n",
    "    \n",
    "    # Channel units\n",
    "    channel_units = []\n",
    "    for i in range(data_dict['num_channels']):\n",
    "        try:\n",
    "            channel_units.append(units[data_dict['channel_titles'][i]])\n",
    "        except:\n",
    "            channel_units.append('MysteryChannelUnits')\n",
    "        \n",
    "    # Channel scales\n",
    "    channel_scales = []\n",
    "    for i in range(data_dict['num_channels']):\n",
    "        try:\n",
    "            channel_scales.append(scale[data_dict['channel_titles'][i]])\n",
    "        except:\n",
    "            channel_scales.append('1.0')\n",
    "            \n",
    "   \n",
    "    ############################################################################\n",
    "    # Convert channel titles passed in dict to binary strings\n",
    "    ############################################################################\n",
    "    \n",
    "    # New list for binary channel titles\n",
    "    bin_channel_titles = []\n",
    "    for i in range(data_dict['num_channels']):\n",
    "        bin_channel_titles.append(\\\n",
    "                                data_dict['channel_titles'][i].encode('utf-8'))\n",
    "    \n",
    "    ############################################################################\n",
    "    # Append all adibin fields to list of lists\n",
    "    ############################################################################\n",
    "    \n",
    "    # Append file header    \n",
    "    adibin_header = []\n",
    "    \n",
    "    adibin_header.append(magic)\n",
    "    adibin_header.append(version)\n",
    "    adibin_header.append(secs_per_tick)\n",
    "    adibin_header.append(year)\n",
    "    adibin_header.append(month)\n",
    "    adibin_header.append(day)\n",
    "    adibin_header.append(hour)\n",
    "    adibin_header.append(minute)\n",
    "    adibin_header.append(second)\n",
    "    adibin_header.append(trigger)\n",
    "    adibin_header.append(data_dict['num_channels'])\n",
    "    adibin_header.append(data_dict['samples_per_channel'])\n",
    "    adibin_header.append(time_channel)\n",
    "    adibin_header.append(data_format)\n",
    " \n",
    "    # Append channel headers\n",
    "    adibin_channel_headers = []\n",
    "\n",
    "    for i in range(data_dict['num_channels']):\n",
    "        adibin_channel_headers.append(bin_channel_titles[i])\n",
    "        adibin_channel_headers.append(channel_units[i])\n",
    "        adibin_channel_headers.append(channel_scales[i])\n",
    "        adibin_channel_headers.append(offset)\n",
    "        adibin_channel_headers.append(range_high)\n",
    "        adibin_channel_headers.append(range_low)\n",
    "        \n",
    "    # Append interleaved channel data\n",
    "    adibin_channel_data = []\n",
    "    \n",
    "    for j in range(data_dict['samples_per_channel']):\n",
    "        for i in range(data_dict['num_channels']):\n",
    "            adibin_channel_data.append(data_dict['channel_data'][i][j])\n",
    "        \n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    # Pack adibin data into writable struct buffers\n",
    "    ############################################################################\n",
    "    \n",
    "    # Pack file header\n",
    "    file_header_buffer = bytearray(FILE_HEADER_LENGTH)\n",
    "    \n",
    "    struct.pack_into(\n",
    "        ADI_FILE_HEADER_FORMAT_STRING\n",
    "        , file_header_buffer\n",
    "        , 0\n",
    "        , *adibin_header\n",
    "        )\n",
    "\n",
    "    # Pack channel headers\n",
    "    channel_headers_format_string = ADI_CHANNEL_HEADER_FORMAT_STRING\n",
    "    for i in range(data_dict['num_channels'] - 1):\n",
    "        channel_headers_format_string += ADI_CHANNEL_HEADER_FORMAT_STRING[1:]\n",
    "    \n",
    "    channel_headers_buffer = bytearray((data_dict['num_channels']) \\\n",
    "                                       * CHANNEL_HEADER_LENGTH)\n",
    "\n",
    "    struct.pack_into(\n",
    "        channel_headers_format_string\n",
    "        , channel_headers_buffer\n",
    "        , 0\n",
    "        , *adibin_channel_headers\n",
    "        )\n",
    "\n",
    "    # Pack channel data    \n",
    "    channel_data_format_string = ADI_CHANNEL_DATA_FORMAT_STRING\n",
    "    for i in range(\\\n",
    "        ((data_dict['num_channels'])*(data_dict['samples_per_channel']))- 1):\n",
    "        channel_data_format_string += ADI_CHANNEL_DATA_FORMAT_STRING[1:]\n",
    "    \n",
    "    channel_data_buffer = bytearray(struct.calcsize(channel_data_format_string))\n",
    "    \n",
    "    struct.pack_into(\n",
    "        channel_data_format_string\n",
    "        , channel_data_buffer\n",
    "        , 0\n",
    "        , *adibin_channel_data\n",
    "        )\n",
    "\n",
    "    \n",
    "    ############################################################################\n",
    "    # Debug: Check values\n",
    "    ############################################################################\n",
    "    if dbg == True:\n",
    "        print(\"channel_units:\", channel_units)\n",
    "        print(\"channel_scales:\", channel_scales)\n",
    "        print(\"adibin_data[0]:\", adibin_data[0])\n",
    "        print('\\n')\n",
    "        \n",
    "        \n",
    "    ############################################################################\n",
    "    # Return packed adibin buffers\n",
    "    ############################################################################\n",
    "    \n",
    "    # Create dictionary of packed buffers for return\n",
    "    adibin_data = {'patient_id': data_dict['patient_id']\n",
    "                  , 'time_since_admission': data_dict['time_since_admission']\n",
    "                  , 'file_header': file_header_buffer\n",
    "                  , 'channel_headers': channel_headers_buffer\n",
    "                  , 'channel_data': channel_data_buffer\n",
    "                  }\n",
    "    \n",
    "    return adibin_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write ADIBIN Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeAdibin(adibin_data, output_directory, dbg=False):\n",
    "    \n",
    "    #Create Filename\n",
    "    filename = output_directory \\\n",
    "                + adibin_data['patient_id'] \\\n",
    "                + \"_\" \\\n",
    "                + adibin_data['time_since_admission'] \\\n",
    "                + \".adibin\"\n",
    "    \n",
    "    # Write the returned content to a file in the output directory\n",
    "    adibin_file = open(filename, 'wb') #overwrite previous file without warning\n",
    "    adibin_file.write(adibin_data['file_header'])\n",
    "    adibin_file.write(adibin_data['channel_headers'])\n",
    "    adibin_file.write(adibin_data['channel_data'])\n",
    "    adibin_file.close()\n",
    "\n",
    "    if dbg == True:\n",
    "        print(\"Writing:\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice CSV to ADIBIN Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csvToAdibin(csv_filename, adibin_out_directory_path, dbg=False):\n",
    "    \n",
    "    # Open CSV File\n",
    "    csv_file = open(csv_filename)\n",
    "    csv_file_reader = csv.reader(csv_file)\n",
    "    \n",
    "    # Parse and write out ADIBIN for every row in the CSV\n",
    "    for row in csv_file_reader:\n",
    "        writeAdibin(createAdibin(parseCsv(row, dbg=False), dbg=False)\n",
    "                   , adibin_out_directory_path\n",
    "                   , dbg = dbg\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing: ./testOutsAdibin/ea6392983e1786204d56da60f29cb2dc_41842.adibin\n",
      "Writing: ./testOutsAdibin/501d5ed00964868b6115eb924681851e_46596.adibin\n",
      "Writing: ./testOutsAdibin/4675480aed8a2b6aa25bc49fd262606e_47092.adibin\n",
      "Writing: ./testOutsAdibin/1b8d5d2955ec9afd70cbddd74cb1fba7_47102.adibin\n",
      "Writing: ./testOutsAdibin/9b473ecda5b3aa8253521b71db7db565_47112.adibin\n",
      "Writing: ./testOutsAdibin/1c971c84e514d1c043556a27fe580cb7_47124.adibin\n",
      "Writing: ./testOutsAdibin/386a268a90055b01306ffab65eadb70d_47132.adibin\n",
      "Writing: ./testOutsAdibin/dbecd410a1f9606312591328ad29e894_47134.adibin\n",
      "Writing: ./testOutsAdibin/248f8fa283c65fd69a951f05ece9d00c_47560.adibin\n",
      "Writing: ./testOutsAdibin/79db2b5bffad61509bf663b3068768b3_44842.adibin\n",
      "Writing: ./testOutsAdibin/5862f0e233189b4ed8fad491511c5f0d_44864.adibin\n",
      "Writing: ./testOutsAdibin/64de22cafb7cbdb4cc413ebd2f0066e9_44020.adibin\n",
      "Writing: ./testOutsAdibin/7cf134c49c429facf53b1bae9a4eddb0_44034.adibin\n",
      "Writing: ./testOutsAdibin/c0e48c8d7149757c36e39c1450db531b_44038.adibin\n",
      "Writing: ./testOutsAdibin/ba0289f29200da168d1266202a2c45a1_44062.adibin\n",
      "Writing: ./testOutsAdibin/ab02dee7328ea4db6e97ae04cff49062_44188.adibin\n",
      "Writing: ./testOutsAdibin/456c979ca0e24df46d1be532c88c8e3a_44210.adibin\n",
      "Writing: ./testOutsAdibin/737ab3592330a2939e43167ab4b1d98a_44242.adibin\n",
      "Writing: ./testOutsAdibin/ea7efd91356bf00a31ed74cde71310cd_33223.adibin\n",
      "Writing: ./testOutsAdibin/8baa9a373eb895e0c5bdb73eafb6d70e_33225.adibin\n",
      "Writing: ./testOutsAdibin/12841ca347bade78913d5d36f9eed9d7_33319.adibin\n",
      "Writing: ./testOutsAdibin/a8cf1e06c31bbc9f183297827353e9c8_33365.adibin\n",
      "Writing: ./testOutsAdibin/c8f70eed976909f633d7a5a9abb41438_32451.adibin\n",
      "Writing: ./testOutsAdibin/4825e2330c4d92ca2cfda795009686e8_32537.adibin\n",
      "Writing: ./testOutsAdibin/a711457e1e816e13a0d74784e167f559_32597.adibin\n",
      "Writing: ./testOutsAdibin/6ee2180a3cb114cc194ee5d6cf6c5835_32791.adibin\n",
      "Writing: ./testOutsAdibin/f6ffe19ca95218a5b4e178166b80f52b_32817.adibin\n",
      "Writing: ./testOutsAdibin/b374d419df1db6949fefd2d45e04f99f_33043.adibin\n",
      "Writing: ./testOutsAdibin/498295b9250b5c259bf22ac26bfd17ce_36999.adibin\n",
      "Writing: ./testOutsAdibin/3ec2093fa16fa19286878a51fde119e9_37001.adibin\n",
      "Writing: ./testOutsAdibin/4c7eb3a90bd2f20e4b95f6ada81e12b3_37027.adibin\n",
      "Writing: ./testOutsAdibin/d9f1964f0943b3cb4540cc7411da6fd1_37225.adibin\n",
      "Writing: ./testOutsAdibin/4ba3406d453e3254a9f9ca14534eb423_37235.adibin\n",
      "Writing: ./testOutsAdibin/367123d7bffa8e4780c68ba11bdae420_37241.adibin\n",
      "Writing: ./testOutsAdibin/6f5ba5499b11198e31ac9a025d85afd4_37245.adibin\n",
      "Writing: ./testOutsAdibin/dd448705dcf667bed26b2ddcf48bea96_37333.adibin\n",
      "Writing: ./testOutsAdibin/18985e820ac5978cfb4bd473a830ee8d_37353.adibin\n",
      "Writing: ./testOutsAdibin/d584dcb2e1bf664a097fd5e9ea6248c8_37363.adibin\n",
      "Writing: ./testOutsAdibin/87469e1716cbf925a23f7a86153e155e_37373.adibin\n",
      "Writing: ./testOutsAdibin/affce9416c006bf47fb41235117e5d19_37375.adibin\n",
      "Writing: ./testOutsAdibin/e15bad38df7cc81ac9827f292c49c5c0_39091.adibin\n",
      "Writing: ./testOutsAdibin/2ca99016f95c611c9eda63b72b60732f_32113.adibin\n",
      "Writing: ./testOutsAdibin/bca14734354a8d488de114738ec3eff8_32205.adibin\n",
      "Writing: ./testOutsAdibin/d0bc36e5fb12c4a0f3b180ea84ffc70a_35859.adibin\n",
      "Writing: ./testOutsAdibin/42d1038ea6b7d0c25405d48635444bb1_35991.adibin\n",
      "Writing: ./testOutsAdibin/7efaa52a539e89b5900b160967ff0626_36161.adibin\n",
      "Writing: ./testOutsAdibin/006f16e01549a41b34c2f3e1dfb1a732_36177.adibin\n",
      "Writing: ./testOutsAdibin/a08f1dde5901d478ceb93fb8958d8940_36189.adibin\n",
      "Writing: ./testOutsAdibin/08bdfd0c2515ba992d30d906dc70bd49_36191.adibin\n",
      "Writing: ./testOutsAdibin/2db556527af8c31df394cb3c92d5bc65_36273.adibin\n",
      "Writing: ./testOutsAdibin/374eabe1aff61e430a9fdbdefa97fe17_36281.adibin\n",
      "Writing: ./testOutsAdibin/26dfd65d18640c62c919767e8abc6fc2_36285.adibin\n",
      "Writing: ./testOutsAdibin/a315c44f96fe9cb0e7ea1d2a3f3b7e45_30567.adibin\n",
      "Writing: ./testOutsAdibin/c76764973d54dc98aa4a7feda2fa7ca6_30573.adibin\n",
      "Writing: ./testOutsAdibin/ebe550974dcf5a9c7ddd9898ce72620a_37473.adibin\n",
      "Writing: ./testOutsAdibin/0f42954cffd64e932eefabf7f4b88488_37699.adibin\n",
      "Writing: ./testOutsAdibin/5a820925015bd4e75f45bfc43bad3e41_37707.adibin\n",
      "Writing: ./testOutsAdibin/e5bc4374b0b50042113002c2120578a6_37711.adibin\n",
      "Writing: ./testOutsAdibin/ef81e89c90af0b3aa004a35b6b50e07d_37715.adibin\n",
      "Writing: ./testOutsAdibin/c1a1f31f49a7a995327c1e1cc90de715_37885.adibin\n",
      "Writing: ./testOutsAdibin/3d5c8aa3314360a4f5577be73d147219_37945.adibin\n",
      "Writing: ./testOutsAdibin/b1e317e016fa50a36b3b5181e5a27c8e_37951.adibin\n",
      "Writing: ./testOutsAdibin/b7669c3e460532321f7bcb270e45660a_37963.adibin\n",
      "Writing: ./testOutsAdibin/bae3ebbe031612b6254188be99074c11_38111.adibin\n",
      "Writing: ./testOutsAdibin/e279e6e216ed658cd333de4520c2e6d7_38133.adibin\n",
      "Writing: ./testOutsAdibin/5958398bbf233fbc340a4690649285c5_40346.adibin\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = \"./sampleFiles/4b80ff2eb1112815299d7a4e9a4a1957.csv\"\n",
    "adibin_directory_path = \"./testOutsAdibin/\"\n",
    "\n",
    "\n",
    "csvToAdibin(csv_file_name, adibin_directory_path, dbg=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
