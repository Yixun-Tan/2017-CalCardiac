{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import csv, pprint, json, base64, \n",
    "import zlib, struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Global Vars & Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Relevant Python Documentation for Reading C Structs into Python](https://docs.python.org/3.5/library/struct.html \"Python Docs for C Structs\")\n",
    "\n",
    "ADIBinaryFormat.h and helpful links copied in comments at end of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers Match :)\n",
      "Channel Titles Match :)\n"
     ]
    }
   ],
   "source": [
    "# Global Variables for ADIBIN file structure\n",
    "HEADER_LENGTH = 68\n",
    "CHANNEL_TITLE_LENGTH = 96\n",
    "\n",
    "# Format Strings to parse C Structs in Python\n",
    "# ADIBinaryFormat.h dictates little endian format - leading '<' in format string\n",
    "# s = multiple char as one, l = long, d = double\n",
    "# 4s = 4 char are first item, read in as one, followed by one long, one double, etc.\n",
    "# 32s = 32 char, read in as first and second item, followed by 4 doubles, read in each separately\n",
    "ADI_FILE_HEADER_FORMAT_STRING = \"<4sldlllllddllll\"\n",
    "sizeHeader=struct.calcsize(ADI_FILE_HEADER_FORMAT_STRING)\n",
    "\n",
    "ADI_CHANNEL_TITLE_FORMAT_STRING = \"<32s32sdddd\"\n",
    "sizeChannel=struct.calcsize(ADI_CHANNEL_TITLE_FORMAT_STRING)\n",
    "\n",
    "\n",
    "# Sanity Check - Make sure format string templates length match global variables for lengths\n",
    "# Lengths specified in ADIBinaryFormat.h file - documentation on adibin files\n",
    "# File Header is 68 bytes and Channel Titles are 96 bytes\n",
    "if (sizeHeader == HEADER_LENGTH):\n",
    "    print('Headers Match :)')\n",
    "else:\n",
    "    print('Headers Mismatch :(')\n",
    "\n",
    "if (sizeChannel == CHANNEL_TITLE_LENGTH):\n",
    "    print('Channel Titles Match :)')\n",
    "else:\n",
    "    print('Channel Titles Mismatch :(')\n",
    "    \n",
    "    #print(sizeHeader, sizeChannel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse ADIBIN Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseChannels(byteBuffer):\n",
    "    \n",
    "    #Start at the beginning of the buffer\n",
    "    byteBuffer.seek(0)\n",
    "    \n",
    "    #Parse File Header\n",
    "    fileHeader = byteBuffer.read(HEADER_LENGTH)\n",
    "    \n",
    "    Magic\\\n",
    "    , Version\\\n",
    "    , secsPerTick\\\n",
    "    , Year\\\n",
    "    , Month\\\n",
    "    , Day\\\n",
    "    , Hour\\\n",
    "    , Minute\\\n",
    "    , Second\\\n",
    "    , trigger\\\n",
    "    , NChannels\\\n",
    "    , SamplesPerChannel\\\n",
    "    , TimeChannel\\\n",
    "    , DataFormat\\\n",
    "    = struct.unpack(ADI_FILE_HEADER_FORMAT_STRING, fileHeader)\n",
    "    \n",
    "    #sanity check\n",
    "    print(Magic.decode('utf-8'))\n",
    "    print(NChannels)\n",
    "    print(SamplesPerChannel)\n",
    "    print('---')\n",
    "    \n",
    "    #Figure out length of rest of the file by checking DataFormat and SamplesPerChannel\n",
    "    #DataFormat 1=double, 2=float, 3=16-bit integer\n",
    "    #sizeof(double) = 8 bytes, sizeof(float) = 4 bytes, sizeof(16-bit integer) = 2 bytes\n",
    "    if (DataFormat == 1):\n",
    "        channelsLength = SamplesPerChannel*8\n",
    "    elif (DataFormat == 2):\n",
    "        channelsLength = SamplesPerChannel*4\n",
    "    elif (DataFormat == 3): \n",
    "        channelsLength = SamplesPerChannel*2\n",
    "    else:\n",
    "        print('DataFormat Not Coded to 1,2,or 3 - Exception')\n",
    "        channelsLength = 0\n",
    "    \n",
    "    #Create python array to store parsed channels\n",
    "    #Order of entries in the array:\n",
    "    #columns=['ChannelIndex','ChannelTitle', 'Units', 'Scale', 'Offset', 'RangeHigh', 'RangeLow','SignalData']\n",
    "    channelArray = []    \n",
    "    \n",
    "    #Parse Channel Titles\n",
    "    for i in range(0, NChannels):\n",
    "        \n",
    "        #Read Channel Titles\n",
    "        channelTitleBuffer = byteBuffer.read(CHANNEL_TITLE_LENGTH)\n",
    "        \n",
    "        #Parse Channel Title Fields\n",
    "        ChannelTitle, Units, Scale, offset, RangeHigh, RangeLow \\\n",
    "        = struct.unpack(ADI_CHANNEL_TITLE_FORMAT_STRING, channelTitleBuffer)\n",
    "        \n",
    "        #sanity check\n",
    "        print(ChannelTitle.decode('utf-8'))\n",
    "        print(Scale)\n",
    "        print(offset)\n",
    "        print('---')\n",
    "        \n",
    "        #Decode Fields Binary Format ######################################not working properly##################\n",
    "        ct = ChannelTitle.decode('utf-8')\n",
    "        u = Units.decode('utf-8')\n",
    "        s = Scale\n",
    "        o = offset\n",
    "        rh = RangeHigh\n",
    "        rl = RangeLow\n",
    "        \n",
    "        #Append Channel Title Fields to array\n",
    "        channelArray.append([i, ct, u, s, o, rh, rl])\n",
    "    \n",
    "    #sanity check\n",
    "    #print(channelArray)\n",
    "    #print('---')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####################################################################not yet validated########################\n",
    "    #Parse Channel Signals\n",
    "    for i in range(0, NChannels):\n",
    "        \n",
    "        #Read Channel Signal\n",
    "        #Using channelsLength from DataFormat, \n",
    "        #scale and offset are used to convert 16-bit samples into user units,\n",
    "        #where data = scale * (sample + offset)\n",
    "        iScale = channelArray[i][3]\n",
    "        iOffset = channelArray[i][4]\n",
    "        iData = iScale * (channelsLength + iOffset)\n",
    "        iData = int(iData)\n",
    "        channelSignalBuffer = byteBuffer.read(iData)\n",
    "        channelArray[i].append(channelSignalBuffer)\n",
    "        \n",
    "        #print(channelSignalBuffer)\n",
    "        #print('\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "    \n",
    "    #sanity check\n",
    "    #print(channelArray)\n",
    "    #print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read & Parse ADIBIN File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adibinFilename = \"./sampleFiles/example.adibin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFWB\n",
      "10\n",
      "7201\n",
      "---\n",
      "I\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "2.44\n",
      "0.0\n",
      "---\n",
      "II\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "2.44\n",
      "0.0\n",
      "---\n",
      "III\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "2.44\n",
      "0.0\n",
      "---\n",
      "V\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "2.44\n",
      "0.0\n",
      "---\n",
      "AVR\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "2.44\n",
      "0.0\n",
      "---\n",
      "AVL\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "2.44\n",
      "0.0\n",
      "---\n",
      "AVF\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "2.44\n",
      "0.0\n",
      "---\n",
      "AR2\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "0.2\n",
      "0.0\n",
      "---\n",
      "SPO2\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "1.0\n",
      "0.0\n",
      "---\n",
      "RR\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "0.1\n",
      "0.0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#Read in adibin file, print\n",
    "with open(adibinFilename, \"rb\") as adibin_file:\n",
    "    #Parse adibin File\n",
    "    parseChannels(adibin_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP/Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145048\n"
     ]
    }
   ],
   "source": [
    "with open(adibinFilename, \"rb\") as adibin_file:\n",
    "    #Parse adibin File\n",
    "    adibin_file.seek(0, 2)  # Seek the end\n",
    "    num_bytes = adibin_file.tell()  # Get the file size\n",
    "    print(num_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1028"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers_numbytes = 68+10*96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144020"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "145048-1028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#samples per channel = 7201\n",
    "#where data = scale * (sample + offset)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base64ToJson(zippedString):\n",
    "    json_str = zlib.decompress(base64.b64decode(zippedString)).decode()\n",
    "    json_json = json.loads(json_str)\n",
    "    return json_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#debugging purpose only - clean out array\n",
    "channelArray = []\n",
    "print(channelArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in File Header and First Channel Title\n",
    "with open(adibinFilename, \"rb\") as adibin_file:\n",
    "    # Read the whole file at once\n",
    "    #data = binary_file.read()\n",
    "    #print(data)\n",
    "    \n",
    "    adibin_file.seek(0)  # Go to beginning\n",
    "    fileHeader = adibin_file.read(68)\n",
    "    #channelTitle = adibin_file.read(96)\n",
    "    print(fileHeader)\n",
    "    #print('\\n')\n",
    "    #print(channelTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Magic, Version, secsPerTick, Year, Month, Day, Hour, Minute, Second, trigger, NChannels, SamplesPerChannel,\\\n",
    "    TimeChannel, DataFormat = struct.unpack(fileHeaderFormatString, fileHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NChannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fileHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(channelTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tupleFileHeader = struct.unpack(fileHeaderFormatString, fileHeader)\n",
    "tupleChannelHeader = struct.unpack(channelTitleFormatString, channelTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tupleFileHeader)\n",
    "print('\\n')\n",
    "print(tupleChannelHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChannelTitle, Units, Scale, offset, RangeHigh, RangeLow = struct.unpack(channelTitleFormatString, channelTitle)\n",
    "print(ChannelTitle)\n",
    "print('\\n')\n",
    "print(ChannelTitle.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Excellent code snippets for working with Binary data in Python](https://www.devdungeon.com/content/working-binary-data-python \"DevDungeon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Note from Jacob Abba defining data format for CSV Patient ECG Files:\n",
    "\n",
    "\n",
    "The csv is a sample of the format that I’ll be providing. \n",
    "\n",
    "Each CSV file will represent a single admission in a bed, \n",
    "and its filename is an encrypted version of that admission’s ID in our database.\n",
    " \n",
    "Each row in the CSV represents a PVC-type alarm from that admission. \n",
    "The first column is an encrypted version of the alarm’s ID in our database. \n",
    "The second column is the time that the alarm occurred (in number of seconds since the start of the admission). \n",
    "The third column is the strip data for that alarm, which has been deflated and base64 encoded. \n",
    "Note that the rows in these files aren’t sorted in any particular order.\n",
    " \n",
    "To get the strip data, simply use a library in your language of choice to read the base64 string to a buffer, \n",
    "deflate the buffer, and then encode the buffer into a string. In nodejs it looks something like this:\n",
    " \n",
    "let zlib = require(‘zlib’);\n",
    " \n",
    "let s = strip; //load strip\n",
    "let buf = Buffer.from(s, 'base64'); //read strip into buffer\n",
    "let json = zlib.unzipSync(buf).toString(); //deflate buffer and convert to a string\n",
    " \n",
    "Once decoded, the strip is an array in JSON format and looks something like this (without the pretty print):\n",
    " \n",
    "[\n",
    "    {\"Label\":\"I\",\"ID\":\"7\",\"Text\":\"-263,-211,-146,-108,-68,-35,3,…”},\n",
    "    {\"Label\":\"II\",\"ID\":\"8\",\"Text\":\"-312,-272,-220,-177,-137,-111,…”},\n",
    "    …\n",
    "]\n",
    " \n",
    "Pretty self-descriptive; each object within the array represents a channel where \n",
    "the “Label” field contains the label, \n",
    "the “Text” field contains the waveform (with each sample separated by a comma). \n",
    "You can probably ignore the “ID” field, it’s just used internally by bedmaster.\n",
    " \n",
    "A few notes on these strips:\n",
    "1)      In our meeting Xiao and Ran said that they contain data 5 seconds before and 5 seconds after an alarm. \n",
    "As far as I can tell this is not correct; they seem to only contain data 10 seconds before the alarm. \n",
    "For your purposes this shouldn’t matter, but it’s good to know.\n",
    "\n",
    "2)      Sampling frequency of the channels is always 240hz.\n",
    "\n",
    "3)      Some files may contain different numbers of channels. \n",
    "Originally we were planning on only using files that had the \n",
    "8 channels (‘I’, ‘II’, ‘III’, ‘V’, ‘AVR’, ‘AVL’, ‘AVF’, and ‘SPO2’), \n",
    "and discarding other channels. But Ran and Xiao would be able to guide you better on how to handle this.\n",
    "\n",
    " \n",
    "For the rules to automatically sort pvc alarms into true- and false-positive categories, \n",
    "you’ll also need timing of artifact alarms for each admission. \n",
    "I’ll work on a script to generate these as well, but it should be simpler since they don’t need to include strips. \n",
    "My plan is to just have text files for each admission (same name as the csv) \n",
    "with each line representing the relative timing of that alarm.\n",
    " \n",
    "You can see Xiao’s earlier email with documentation on the adibin file format.\n",
    " \n",
    "Hopefully this info is helpful to you, \n",
    "if anything is unclear or you need guidance on data conversion/reading the csv then \n",
    "feel free to reach out via text or email!\n",
    " \n",
    "Jacob\n",
    "'''\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code in ADIBinaryFormat.h that shows the structure of the FileHeader and Channel Titles\n",
    "\n",
    "/***************************************************************************\n",
    " * Translate Binary for LabChart for Windows\n",
    " *\n",
    " * ADIBinaryFormat.h\n",
    " *\n",
    " * Copyright (c) 2001-2009 ADInstruments Ltd.\n",
    " *\n",
    " * Translate Binary is a LabChart for Windows extension that enables data to be\n",
    " * moved to and from LabChart, in a simple binary format.\n",
    " *\n",
    " * A LCfW binary file has the following structure:\n",
    " *\n",
    " *  - A 68 byte file header (CFWBINARY structure) containing basic information\n",
    " *   about the data such as the sampling period, number of channels, trigger\n",
    " *   time, data format.\n",
    " *\n",
    " *  - For each channel, a 96 byte channel header (CFWBCHANNEL structure)\n",
    " *   containing information about the channel.\n",
    " *\n",
    " *  - The interleaved channel data. Data can be either double precision\n",
    " *   floating point, single precision floating point or 16 bit integer, as\n",
    " *   specified by the DataFormat parameter of the file header.\n",
    " *\n",
    " *\n",
    " * The CFWBINARY and CFWBCHANNEL structures are defined below, along with a\n",
    " * simple program which creates a two channel CfW binary file.\n",
    " *\n",
    " * Note that the following types must have the indicated size and that the\n",
    " * program needs to be run on a little endian machine (e.g. x86):\n",
    " *\n",
    " * sizeof(char)   = 1 byte\n",
    " * sizeof(short)  = 2 bytes\n",
    " * sizeof(long)   = 4 bytes\n",
    " * sizeof(double) = 8 bytes, i.e. 64 bit IEEE floating point\n",
    " *\n",
    " ******************************************************************************/\n",
    "#ifndef _ADIBinFormat\n",
    "#define _ADIBinFormat\n",
    "\n",
    "#define CHANNEL_TITLE_LEN  32\n",
    "#define UNITS_LEN          32\n",
    "#define CFWB_VERSION       1\n",
    "\n",
    "enum \n",
    "   {\n",
    "   kBinFmtDouble  =  1,\n",
    "   kBinFmtFloat,\n",
    "   kBinFmtInt16,\n",
    "   };\n",
    "\n",
    "// The file and header structures must be packed on 1-byte boundaries.\n",
    "// On Visual C++ the following pragma enforces this.\n",
    "#pragma pack(1)\n",
    "\n",
    "// Each LabChart for Windows binary file starts with the following structure:\n",
    "struct CFWBINARY\n",
    "   {\n",
    "   char     magic[4];            // always \"CFWB\"\n",
    "   long     Version;             // = CFWB_VERSION\n",
    "   double   secsPerTick;         // sampling interval in seconds\n",
    "\n",
    "   // Trigger Date and time information\n",
    "   long    Year;                // 4 digit year\n",
    "   long    Month;               // months 1 - 12\n",
    "   long    Day;                 // days 1 - 31\n",
    "   long    Hour;                // hours 0 - 23\n",
    "   long    Minute;              // minutes 0 - 59\n",
    "   double   Second;              // seconds\n",
    "   double   trigger;             // Amount of pretrigger data in seconds.\n",
    "\n",
    "   long     NChannels;           // Number of channels\n",
    "   long     SamplesPerChannel;   // Number of sample points per channel\n",
    "   \n",
    "   // The TimeChannel flag indicates that the sample time of each sample is\n",
    "   // interleaved as the first column of data. This is only valid for the floating\n",
    "   // point data formats. For all releases of TranslateBinary up to and including\n",
    "   // v1.3, sample time data can be included but it is not used.\n",
    "   long     TimeChannel;         // 1 = time included as first channel, 0 = not included\n",
    "   long     DataFormat;          // 1 = double , 2 = float, 3 = 16-bit integer\n",
    "   };\n",
    "\n",
    "// Then one of these for each of the 'NChannels':\n",
    "struct CFWBCHANNEL\n",
    "   {\n",
    "   char     Title[CHANNEL_TITLE_LEN];  // Channel title string\n",
    "   char     Units[UNITS_LEN];          // Channel units string\n",
    "\n",
    "   // scale and offset are used to convert 16-bit samples into user units,\n",
    "   // where  data = scale * (sample + offset)\n",
    "   double   scale;                     // scale (= 1.0 for floating point data)\n",
    "   double   offset;                    // offset (= 0.0 for floating point data)\n",
    "\n",
    "   // The maximum and minimum values of the data\n",
    "   // (not used in TranslateBinary up to and including v1.3)\n",
    "   double   RangeHigh;\n",
    "   double   RangeLow;\n",
    "   };\n",
    "\n",
    "// Back to default data structure packing\n",
    "#pragma pack()\n",
    "\n",
    "#endif   // sentinelRangeLow;\n",
    "   };\n",
    "\n",
    "// Back to default data structure packing\n",
    "#pragma pack()\n",
    "\n",
    "#endif   // sentinel\n",
    "\n",
    "'''\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Pandas Dataframe to hold parsed channels header and data\n",
    "    #dfAdi = pandas.DataFrame(\\\n",
    "    #                        columns=['ChannelIndex',\\\n",
    "    #                                 'ChannelTitle', 'Units', 'Scale', 'Offset', 'RangeHigh', 'RangeLow', \\\n",
    "    #                                 'SignalData']\n",
    "    #                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(adibinFilename, \"rb\") as binary_file:\n",
    "    data = binary_file.read()\n",
    "    \n",
    "    binary_file.seek(0)\n",
    "    magic = binary_file.read(4)\n",
    "    print(magic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(adibinFilename, \"rb\") as binary_file:\n",
    "    data = binary_file.read()\n",
    "    \n",
    "    binary_file.seek(0)\n",
    "    magic = binary_file.read(4)\n",
    "    version = binary_file.read(4)\n",
    "    intVersion = int.from_bytes(version, byteorder='little')\n",
    "    secsPerTick = binary_file.read(8)\n",
    "    intSecsPerTick = int.from_bytes(secsPerTick, byteorder='little')\n",
    "    print(magic, version, intVersion, secsPerTick, intSecsPerTick)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf-8')\n",
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(adibinFilename, \"rb\") as binary_file:\n",
    "    # Read the whole file at once\n",
    "    data = binary_file.read()\n",
    "    #print(data)\n",
    "    \n",
    "    binary_file.seek(0)  # Go to beginning\n",
    "    couple_bytes = binary_file.read(68)\n",
    "    print(couple_bytes.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_data = b'test'\n",
    "text = binary_data.decode('utf-8')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(binary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base64_data = codecs.encode(binary_data, 'base64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(binary_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(base64_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base64_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.append(['abc', 'cde'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.append(['def'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1].append('qwe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
