{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv, pprint, json, struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import base64, zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def base64ToJson(zippedString):\n",
    "    json_str = zlib.decompress(base64.b64decode(zippedString)).decode()\n",
    "    json_json = json.loads(json_str)\n",
    "    return json_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "csv_filename = \"./sampleFiles/4b80ff2eb1112815299d7a4e9a4a1957.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # csv_file = open(csv_filename)\n",
    "# csv_reader = csv.reader(csv_file)\n",
    "\n",
    "# for row in csv_reader:\n",
    "#     #print(row)\n",
    "#     print(row[0])\n",
    "#     print(row[1])\n",
    "#     pprint.pprint(base64ToJson(row[2]))\n",
    "#     #break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "csv_data_list = []\n",
    "\n",
    "csv_file = open(csv_filename)\n",
    "csv_reader = csv.reader(csv_file)\n",
    "csv_data_list = list(csv_reader)\n",
    "\n",
    "print(csv_data_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(csv_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(csv_data_list)):\n",
    "#     print(csv_data_list[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(csv_data_list[0][0])\n",
    "print(csv_data_list[0][1])\n",
    "print(len(csv_data_list[0][2]))\n",
    "for i in range(len(csv_data_list[0][2])):\n",
    "    print(csv_data_list[0][2][i]['Label'])\n",
    "print(csv_data_list[0][2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(csv_data_list)):\n",
    "    csv_data_list[i][2] = base64ToJson(csv_data_list[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pprint.pprint(csv_data_list[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(csv_data_list[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "type(csv_data_list[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# csv_data_list[0][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "csv_data_list[0][2][0]['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ID = csv_data_list[0][2][0]['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "type(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Text = csv_data_list[0][2][0]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "type(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "values = [int(i) for i in Text.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Encode binary data to a base 64 string\n",
    "binary_data = b'\\x00' #\\xFF\\x00\\xFF\n",
    "\n",
    "# Use the codecs module to encode\n",
    "import codecs\n",
    "base64_data = codecs.encode(binary_data, 'base64')\n",
    "print(base64_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "decoded_data = codecs.decode(base64_data, 'utf-8')\n",
    "print(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "version = 1 \n",
    "type(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Text to Binary\n",
    "message = \"Hello\"  # str\n",
    "binary_message = message.encode('utf-8')\n",
    "print(type(binary_message))  # bytes\n",
    "print(binary_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Python has many built in encodings for different languages,\n",
    "# and even the Caeser cipher is built in\n",
    "import codecs\n",
    "cipher_text = codecs.encode(message, 'rot_13')\n",
    "print(cipher_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_channels = 3\n",
    "channel_titles = ['I','II','III']\n",
    "units = {'I':'mV' \\\n",
    "       , 'II':'mV' \\\n",
    "       , 'III':'mV' \\\n",
    "       , 'V':'mV' \\\n",
    "       , 'AVR':'mV' \\\n",
    "       , 'AVL':'mV' \\\n",
    "       , 'AVF':'mV'  \\\n",
    "       , 'AR2':'mmHg' \\\n",
    "       , 'SP02':'%' \\\n",
    "       , 'RR':'Imp' \\\n",
    "       , 'RESP':'Imp'\\\n",
    "       , 'Else':'Err'\\\n",
    "       }\n",
    "\n",
    "channel_units = []\n",
    "for i in range(num_channels):\n",
    "    channel_units.append(units[channel_titles[i]])\n",
    "\n",
    "for i in range(num_channels):\n",
    "    print(channel_units[i])\n",
    "    \n",
    "print(channel_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bin_channel_titles = []\n",
    "for i in range(num_channels):\n",
    "    bin_channel_titles.append(channel_titles[i].encode('utf-8'))\n",
    "\n",
    "print(bin_channel_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "CHANNEL_HEADER_LENGTH = 96\n",
    "channel_headers_buffer = bytearray(num_channels \\\n",
    "                                       * CHANNEL_HEADER_LENGTH)\n",
    "\n",
    "print(channel_headers_buffer)\n",
    "print(96*3)\n",
    "print(len(channel_headers_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ADI_CHANNEL_HEADER_FORMAT_STRING = \"<32s32sdddd\"\n",
    "multiplied_fs = ADI_CHANNEL_HEADER_FORMAT_STRING * num_channels\n",
    "print(multiplied_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FILE_HEADER_LENGTH = 68\n",
    "CHANNEL_HEADER_LENGTH = 96\n",
    "CHANNEL_TITLE_LENGTH = 32\n",
    "UNITS_LENGTH = 32\n",
    "    \n",
    "# Define format strings for struct\n",
    "ADI_FILE_HEADER_FORMAT_STRING = \"<4sldlllllddllll\"\n",
    "ADI_CHANNEL_HEADER_FORMAT_STRING = \"<32s32sdddd\"\n",
    "\n",
    "channel_headers_buffer = bytearray(num_channels \\\n",
    "                                       * CHANNEL_HEADER_LENGTH)\n",
    "\n",
    "    \n",
    "full_channel_header_format_string = ADI_CHANNEL_HEADER_FORMAT_STRING\n",
    "for i in range(num_channels - 1):\n",
    "    full_channel_header_format_string += ADI_CHANNEL_HEADER_FORMAT_STRING[1:]\n",
    "    \n",
    "print(full_channel_header_format_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dict = {'channel_data': [[1,2,3,4,5],[11,22,33,44,55],[111,222,333,444,555]]}\n",
    "# Append interleaved channel data\n",
    "adibin_channel_data = []\n",
    "    \n",
    "for j in range(5):\n",
    "    for i in range(num_channels):\n",
    "        adibin_channel_data.append(data_dict['channel_data'][i][j])\n",
    "        print(adibin_channel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ADI_CHANNEL_DATA_FORMAT_STRING = \"<h\"\n",
    "channel_data_format_string = ADI_CHANNEL_DATA_FORMAT_STRING\n",
    "for i in range(2400 - 1):\n",
    "    channel_data_format_string += ADI_CHANNEL_DATA_FORMAT_STRING[1:]\n",
    "    \n",
    "print(len(channel_data_format_string))\n",
    "print(struct.calcsize(channel_data_format_string))\n",
    "print(channel_data_format_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filename = \"abcdefghijklmnopqrstuvwxyz.csv\"\n",
    "onlyname = filename[:-4]\n",
    "print(onlyname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()\n",
    "\n",
    "# \n",
    "# Sample Usage\n",
    "# \n",
    "\n",
    "from time import sleep\n",
    "\n",
    "# A List of Items\n",
    "items = list(range(0, 57))\n",
    "l = len(items)\n",
    "\n",
    "# Initial call to print 0% progress\n",
    "printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 70)\n",
    "for i, item in enumerate(items):\n",
    "    # Do stuff...\n",
    "    sleep(0.1)\n",
    "    # Update Progress Bar\n",
    "    printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def progress(count, total, status=''):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "\n",
    "    sys.stdout.write('[%s] %s%s ...%s\\r' % (bar, percents, '%', status))\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "\n",
    "    \n",
    "import time \n",
    "\n",
    "\n",
    "total = 1000\n",
    "i = 0\n",
    "while i < total:\n",
    "    progress(i, total, status='Doing very long job')\n",
    "    time.sleep(0.5)  # emulating long-playing job\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sqlite3, os, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def csvRowToSqlite(data_dict, csv_filename, output_directory, dbg = False):\n",
    "    \n",
    "#     # Add csv_filename to data_dict for ease\n",
    "#     data_dict.update({'admission_id': csv_filename})\n",
    "    \n",
    "#     # Convert channel titles and channel data to blob fields\n",
    "#     dump = \\\n",
    "#                       pickle.dump(data_dict['channel_titles']\\\n",
    "#                                    , pickle.HIGHEST_PROTOCOL)\\\n",
    "                      \n",
    "#     #data_dict.update({'channel_titles_blob': })\n",
    "    \n",
    "#     # Create default empty dictionary\n",
    "#     default_dict = {\n",
    "#         'admission_id' : 'Default'\n",
    "#         , 'alarm_id' : 'Default'\n",
    "#         , 'time_since_admission' : None\n",
    "#         , 'num_channels' : None\n",
    "#         , 'channel_titles' : None\n",
    "#         , 'channel_data' : None\n",
    "#         , 'samples_per_channel' : None  \n",
    "#     }\n",
    "    \n",
    "#     # If directory does not exist, create it\n",
    "#     os.makedirs(os.path.dirname(output_directory), exist_ok=True)\n",
    "    \n",
    "#     # Open connection to SQLite database\n",
    "#     #  or create database if it doesn't exist\n",
    "#     connection = sqlite3.connect(output_directory + 'errorRows.db')\n",
    "#     cursor = connection.cursor()\n",
    "    \n",
    "#     # Create CSVROWS table if it doesn't exist\n",
    "#     cursor.execute(\n",
    "#     '''\n",
    "#     CREATE TABLE IF NOT EXISTS CSVROWS \n",
    "#         (CSVROW_KEY            INTEGER PRIMARY KEY\n",
    "#         , ADMISSION_ID         VARCHAR(100)\n",
    "#         , ALARM_ID             VARCHAR(100)\n",
    "#         , TIME_SINCE_ADMISSION INTEGER\n",
    "#         , NUM_CHANNELS         INTEGER\n",
    "#         , CHANNEL_TITLES       BLOB\n",
    "#         , CHANNEL_DATA         BLOB\n",
    "#         , SAMPLES_PER_CHANNEL  INTEGER\n",
    "#         );\n",
    "#     ''')\n",
    "    \n",
    "#     # Insert error row into CSVROWS table\n",
    "#     insert_csvRow = \\\n",
    "#     '''\n",
    "#     INSERT INTO CSVROWS\n",
    "#         (ADMISSION_ID\n",
    "#         , ALARM_ID\n",
    "#         , TIME_SINCE_ADMISSION\n",
    "#         , NUM_CHANNELS\n",
    "#         , CHANNEL_TITLES\n",
    "#         , CHANNEL_DATA\n",
    "#         , SAMPLES_PER_CHANNEL\n",
    "#         )\n",
    "#     VALUES\n",
    "#         (:admission_id\n",
    "#         , :alarm_id\n",
    "#         , :time_since_admission\n",
    "#         , :num_channels\n",
    "#         , :channel_titles_blob\n",
    "#         , :channel_data\n",
    "#         , :samples_per_channel\n",
    "#         );\n",
    "#     '''\n",
    "    \n",
    "#     cursor.executemany(insert_sql\\\n",
    "#         , ({k: data_dict.get(k, default_dict[k]) for k in default_dict} \\\n",
    "#         for d in data_dict))\n",
    "#     #cursor.execute(insert_sql, data_dict)\n",
    "    \n",
    "#     # Debug\n",
    "#     if dbg == True:\n",
    "#         cursor.execute(\\\n",
    "#         '''\n",
    "#         SELECT *\n",
    "#         /*\n",
    "#             ADMISSION_ID\n",
    "#             , ALARM_ID\n",
    "#             , TIME_SINCE_ADMISSION\n",
    "#         */\n",
    "#         FROM CSVROWS;\n",
    "#         ''')\n",
    "#         print(\"FETCHALL:\")\n",
    "#         result = cursor.fetchall()\n",
    "#         for r in result:\n",
    "#             print(r)\n",
    "    \n",
    "#     # Commit and close\n",
    "#     connection.commit()\n",
    "#     connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def csvRowToSqlite(data_dict, csv_filename, output_directory, dbg = False):\n",
    "    \n",
    "    # Add csv_filename to data_dict for ease\n",
    "    data_dict.update({'admission_id': csv_filename})\n",
    "    \n",
    "    # Convert channel data to blob fields\n",
    "    dump = pickle.dumps(data_dict['channel_data']\\\n",
    "                       , pickle.HIGHEST_PROTOCOL)\\\n",
    "                      \n",
    "    data_dict.update({'channel_data_blob': })\n",
    "    \n",
    "    # Create default empty dictionary\n",
    "    default_dict = {\n",
    "        'admission_id' : 'Default'\n",
    "        , 'alarm_id' : 'Default'\n",
    "        , 'time_since_admission' : None\n",
    "        , 'num_channels' : None\n",
    "        , 'channel_titles' : None\n",
    "        , 'channel_data' : None\n",
    "        , 'samples_per_channel' : None  \n",
    "    }\n",
    "    \n",
    "    # If directory does not exist, create it\n",
    "    os.makedirs(os.path.dirname(output_directory), exist_ok=True)\n",
    "    \n",
    "    # Open connection to SQLite database\n",
    "    #  or create database if it doesn't exist\n",
    "    connection = sqlite3.connect(output_directory + 'errorRows.db')\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    # Create CSVROWS table if it doesn't exist\n",
    "    cursor.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS CSVROWS \n",
    "        (CSVROW_KEY            INTEGER PRIMARY KEY\n",
    "        , ADMISSION_ID         VARCHAR(100)\n",
    "        , ALARM_ID             VARCHAR(100)\n",
    "        , TIME_SINCE_ADMISSION INTEGER\n",
    "        , NUM_CHANNELS         INTEGER\n",
    "        , CHANNEL_TITLE_KEY    INTEGER\n",
    "        , CHANNEL_DATA         BLOB\n",
    "        , SAMPLES_PER_CHANNEL  INTEGER\n",
    "        );\n",
    "    ''')\n",
    "    \n",
    "    # Create CHANNEL_TITLES table if it doesn't exist\n",
    "    cursor.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS CHANNEL_TITLES\n",
    "        (CHANNEL_TITLE_KEY     INTEGER PRIMARY KEY\n",
    "        , CHANNEL_TITLE        VARCHAR(100) NOT NULL UNIQUE\n",
    "        );\n",
    "    ''')\n",
    "    \n",
    "    # Create view to catch rows to test inserts\n",
    "    cursor.execute(\n",
    "    '''\n",
    "    CREATE VIEW IF NOT EXISTS VIEW_TO_INSERT_CHANNEL AS\n",
    "    SELECT\n",
    "        ADMISSION_ID\n",
    "        , ALARM_ID\n",
    "        , TIME_SINCE_ADMISSION\n",
    "        , NUM_CHANNELS\n",
    "        , CHANNEL_TITLE\n",
    "        , CHANNEL_DATA\n",
    "        , SAMPLES_PER_CHANNEL\n",
    "    FROM CSVROWS\n",
    "        INNER JOIN CHANNEL_TITLES ON \n",
    "            CSVROWS.CHANNEL_TITLE_KEY = CHANNEL_TITLES.CHANNEL_TITLE_KEY\n",
    "    ;\n",
    "    ''')\n",
    "    \n",
    "    # Create trigger to check view inserts and add to databases\n",
    "    cursor.execute(\n",
    "    '''\n",
    "    CREATE TRIGGER IF NOT EXISTS TRIGGER_CHANNELS_FOR_INSERT\n",
    "    INSTEAD OF INSERT\n",
    "    ON VIEW_TO_INSERT_CHANNEL\n",
    "    \n",
    "    BEGIN\n",
    "    \n",
    "    INSERT INTO CHANNEL_TITLES (CHANNEL_TITLE)\n",
    "    SELECT NEW.CHANNEL_TITLE\n",
    "    WHERE NOT EXISTS\n",
    "        (SELECT 1 FROM CHANNEL_TITLES\n",
    "        WHERE CHANNEL_TITLE = NEW.CHANNEL_TITLE);\n",
    "    \n",
    "    INSERT INTO CSVROWS\n",
    "        (ADMISSION_ID\n",
    "        , ALARM_ID\n",
    "        , TIME_SINCE_ADMISSION\n",
    "        , NUM_CHANNELS\n",
    "        , CHANNEL_TITLE_KEY\n",
    "        , CHANNEL_DATA\n",
    "        , SAMPLES_PER_CHANNEL\n",
    "        )\n",
    "    SELECT NEW.ADMISSION_ID\n",
    "        , NEW.ALARM_ID\n",
    "        , NEW.TIME_SINCE_ADMISSION\n",
    "        , NEW.NUM_CHANNELS\n",
    "        , CHANNEL_TITLES.CHANNEL_TITLE_KEY\n",
    "        , NEW.CHANNEL_DATA\n",
    "        , NEW.SAMPLES_PER_CHANNEL\n",
    "    FROM CHANNEL_TITLES\n",
    "    WHERE CHANNEL_TITLES.CHANNEL_TITLE = NEW.CHANNEL_TITLE\n",
    "    ;\n",
    "    \n",
    "    END\n",
    "    ''')\n",
    "    \n",
    "    # Insert string for inserting channel into VIEW_TO_INSERT_CHANNEL\n",
    "    insert_channel = \\\n",
    "    '''\n",
    "    INSERT INTO VIEW_TO_INSERT_CHANNEL\n",
    "        (ADMISSION_ID\n",
    "        , ALARM_ID\n",
    "        , TIME_SINCE_ADMISSION\n",
    "        , NUM_CHANNELS\n",
    "        , CHANNEL_TITLE\n",
    "        , CHANNEL_DATA\n",
    "        , SAMPLES_PER_CHANNEL\n",
    "        )\n",
    "    VALUES\n",
    "        (:admission_id\n",
    "        , :alarm_id\n",
    "        , :time_since_admission\n",
    "        , :num_channels\n",
    "        , :channel_title\n",
    "        , :channel_data\n",
    "        , :samples_per_channel\n",
    "        );\n",
    "    '''\n",
    "    \n",
    "    # Insert error row into VIEW_TO_INSERT_CHANNEL\n",
    "    for i in range(data_dict['num_channels']):\n",
    "        channel_dict = {\n",
    "            'admission_id' : data_dict['admission_id']\n",
    "            , 'alarm_id' : data_dict['alarm_id']\n",
    "            , 'time_since_admission' : data_dict['time_since_admission']\n",
    "            , 'num_channels' : data_dict['num_channels']\n",
    "            , 'channel_title' : data_dict['channel_titles'][i]\n",
    "            , 'channel_data' : data_dict['channel_data']\n",
    "            , 'samples_per_channel' : data_dict['samples_per_channel']  \n",
    "        }\n",
    "            \n",
    "        cursor.executemany(insert_channel\\\n",
    "            , ({k: data_dict.get(k, default_dict[k]) for k in default_dict} \\\n",
    "            for d in channel_dict))\n",
    "        #cursor.execute(insert_sql, data_dict)\n",
    "    \n",
    "    # Debug\n",
    "    if dbg == True:\n",
    "        cursor.execute(\\\n",
    "        '''\n",
    "        SELECT *\n",
    "        /*\n",
    "            ADMISSION_ID\n",
    "            , ALARM_ID\n",
    "            , TIME_SINCE_ADMISSION\n",
    "        */\n",
    "        FROM CSVROWS;\n",
    "        ''')\n",
    "        print(\"FETCHALL:\")\n",
    "        result = cursor.fetchall()\n",
    "        for r in result:\n",
    "            print(r)\n",
    "    \n",
    "    # Commit and close\n",
    "    connection.commit()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dict = \\\n",
    "{\n",
    "    'alarm_id': '111222333'\n",
    "    , 'time_since_admission': '12345'\n",
    "    , 'num_channels': 3\n",
    "    , 'channel_titles': ['I', 'II', 'III']\n",
    "    , 'channel_data': [[1,2,3,4,5], [11,22,33,44,55], [111,222,333,444,555]]\n",
    "    , 'samples_per_channel': 5\n",
    "}\n",
    "\n",
    "csv_filename = '123456789'\n",
    "output_directory = './test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "You did not supply a value for binding 5.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5429eeab1f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcsvRowToSqlite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-a43b528e7d6e>\u001b[0m in \u001b[0;36mcsvRowToSqlite\u001b[0;34m(data_dict, csv_filename, output_directory, dbg)\u001b[0m\n\u001b[1;32m    141\u001b[0m         }\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_channel\u001b[0m            \u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefault_dict\u001b[0m\u001b[0;34m}\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchannel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;31m#cursor.execute(insert_sql, data_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: You did not supply a value for binding 5."
     ]
    }
   ],
   "source": [
    "csvRowToSqlite(data_dict, csv_filename, output_directory, dbg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alexchandra/Documents/Alex/capstone/CalCardiac/branchAlex/dataEngineering/adiConversion\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adibin2csv.py~\t   adiConversion_csv.ipynb  docs\t\t  sampleFiles\r\n",
      "adibinToCsv.ipynb  csvToAdibin.ipynb\t    readWriteDirs\t  test\r\n",
      "adibinToCsv.py\t   csvToAdibin.py\t    readWriteShell.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdata = cPickle.dumps(data, cPickle.HIGHEST_PROTOCOL)\n",
    "curr.execute(\"insert into table (data) values (:data)\", sqlite3.Binary(pdata))\n",
    "You must specify the second argument to dumps to force a binary pickling.\n",
    "Also note the sqlite3.Binary to make it fit in the BLOB field.\n",
    "\n",
    "To retrieve data:\n",
    "curr.execute(\"select data from table limit 1\")\n",
    "for row in curr:\n",
    "  data = cPickle.loads(str(row['data']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
